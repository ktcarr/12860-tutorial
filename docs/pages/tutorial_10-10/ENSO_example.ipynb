{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0294a2d1-ac11-44c6-8d4c-f09066b4ce27",
   "metadata": {},
   "source": [
    "# ENSO example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ea7642-50d7-4e56-b847-f9d0af63f9b5",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daaf53e-f603-40ac-b7a6-968a9eef13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "import cmocean\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.ticker as mticker\n",
    "import scipy.signal\n",
    "import copy\n",
    "import dask.distributed\n",
    "\n",
    "## (optional) remove gridlines from plots\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de6686d-1f50-4cd2-99e3-ec18c930e6c0",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad8ace-6902-4bb7-8b3d-ea4c19d33506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_setup(fig, projection, lon_range, lat_range, xticks=None, yticks=None):\n",
    "    \"\"\"Add a subplot to the figure with the given map projection\n",
    "    and lon/lat range. Returns an Axes object.\"\"\"\n",
    "\n",
    "    ## increase resolution for projection\n",
    "    ## (otherwise lines plotted on surface won't follow curved trajectories)\n",
    "    projection.threshold /= 1000\n",
    "\n",
    "    ## Create subplot with given projection\n",
    "    ax = fig.add_subplot(projection=projection)\n",
    "\n",
    "    ## Subset to given region\n",
    "    extent = [*lon_range, *lat_range]\n",
    "    ax.set_extent(extent, crs=ccrs.PlateCarree())\n",
    "\n",
    "    ## draw coastlines\n",
    "    ax.coastlines(linewidths=0.5)\n",
    "\n",
    "    ## add tick labels\n",
    "    if xticks is not None:\n",
    "\n",
    "        ## add lon/lat labels\n",
    "        gl = ax.gridlines(\n",
    "            draw_labels=True,\n",
    "            linestyle=\"-\",\n",
    "            alpha=0.1,\n",
    "            linewidth=0.5,\n",
    "            color=\"k\",\n",
    "            zorder=1.05,\n",
    "        )\n",
    "\n",
    "        ## specify which axes to label\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "\n",
    "        ## specify ticks\n",
    "        gl.ylocator = mticker.FixedLocator(yticks)\n",
    "        gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_box_outline(ax, lon_range, lat_range):\n",
    "    \"\"\"\n",
    "    Plot box outlining the specifed lon/lat range on given\n",
    "    ax object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## get width and height\n",
    "    height = lat_range[1] - lat_range[0]\n",
    "    width = lon_range[1] - lon_range[0]\n",
    "\n",
    "    ## add rectangle to plot\n",
    "    ax.add_patch(\n",
    "        mpatches.Rectangle(\n",
    "            xy=[lon_range[0], lat_range[0]],\n",
    "            height=height,\n",
    "            width=width,\n",
    "            transform=ccrs.PlateCarree(),\n",
    "            facecolor=\"none\",\n",
    "            edgecolor=\"k\",\n",
    "            linewidth=1,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_correlation(plot_setup_fn, corr, x, y):\n",
    "    \"\"\"\n",
    "    Make spatial plot of correlation, using the specified\n",
    "    plot setup function and pre-computed correlation.\n",
    "    Args:\n",
    "        - plot_setup_fn: function that returns a fig, ax object\n",
    "        - corr: xarray with spatial correlation\n",
    "        - x, y: lon/lat points for plotting\n",
    "    \"\"\"\n",
    "\n",
    "    ## blank canvas to plot on\n",
    "    fig = plt.figure()\n",
    "\n",
    "    ## draw background map of Atlantic\n",
    "    fig, ax = plot_setup_fn(fig)\n",
    "\n",
    "    ## plot the data\n",
    "    plot_data = ax.contourf(\n",
    "        x,\n",
    "        y,\n",
    "        corr,\n",
    "        transform=ccrs.PlateCarree(),\n",
    "        levels=make_cb_range(1, 0.1),\n",
    "        extend=\"both\",\n",
    "        cmap=\"cmo.balance\",\n",
    "    )\n",
    "\n",
    "    ## create colorbath\n",
    "    colorbar = fig.colorbar(plot_data, label=\"Corr.\", ticks=[-1, -0.5, 0, 0.5, 1])\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def make_cb_range(amp, delta):\n",
    "    \"\"\"Make colorbar_range for cmo.balance\n",
    "    Args:\n",
    "        - 'amp': amplitude of maximum value for colorbar\n",
    "        - 'delta': increment for colorbar\n",
    "    \"\"\"\n",
    "    return np.concatenate(\n",
    "        [np.arange(-amp, 0, delta), np.arange(delta, amp + delta, delta)]\n",
    "    )\n",
    "\n",
    "\n",
    "def plot_setup_timeseries():\n",
    "    \"\"\"\n",
    "    Create fig, ax objects and label time axis\n",
    "    \"\"\"\n",
    "\n",
    "    ## set up plot\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "    ## restrict to last 50 years and label axes\n",
    "    ax.set_xlim([datetime.date(1970, 1, 1), None])\n",
    "\n",
    "    ax.set_xticks(\n",
    "        [\n",
    "            datetime.date(1979, 1, 1),\n",
    "            datetime.date(2000, 6, 30),\n",
    "            datetime.date(2021, 12, 31),\n",
    "        ]\n",
    "    )\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def plot_seasonal_cycle(mean, std):\n",
    "    \"\"\"\n",
    "    Plot the seasonal cycle (monthly mean ± 1 standard dev.)\n",
    "    \"\"\"\n",
    "\n",
    "    ## plot\n",
    "    fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "    ## mean\n",
    "    ax.plot(np.arange(1, 13), mean, c=\"k\", label=r\"$\\mu$\")\n",
    "\n",
    "    ## mean ± std\n",
    "    ax.plot(np.arange(1, 13), mean + std, c=\"k\", lw=0.5, label=r\"$\\mu \\pm \\sigma$\")\n",
    "    ax.plot(np.arange(1, 13), mean - std, c=\"k\", lw=0.5)\n",
    "\n",
    "    ## label\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "def spatial_avg(data):\n",
    "    \"\"\"function to compute spatial average of data on grid with constant\n",
    "    longitude/latitude spacing.\"\"\"\n",
    "\n",
    "    ## first, compute cosine of latitude (after converting degrees to radians)\n",
    "    latitude_radians = np.deg2rad(data.latitude)\n",
    "    cos_lat = np.cos(latitude_radians)\n",
    "\n",
    "    ## get weighted average using xarray\n",
    "    avg = data.weighted(weights=cos_lat).mean([\"longitude\", \"latitude\"])\n",
    "\n",
    "    return avg\n",
    "\n",
    "\n",
    "def get_trend(data, dim=\"time\", deg=1):\n",
    "    \"\"\"\n",
    "    Get trend for an xr.dataarray along specified dimension,\n",
    "    by fitting polynomial of degree 'deg'.\n",
    "    \"\"\"\n",
    "\n",
    "    ## Get coefficients for best fit\n",
    "    polyfit_coefs = data.polyfit(dim=dim, deg=deg)[\"polyfit_coefficients\"]\n",
    "\n",
    "    ## Get best fit line (linear trend in this case)\n",
    "    trend = xr.polyval(data[dim], polyfit_coefs)\n",
    "\n",
    "    return trend\n",
    "\n",
    "\n",
    "def detrend(data, dim=\"time\", deg=1):\n",
    "    \"\"\"\n",
    "    Remove trend of degree 'deg' from data, along dimension 'dim'.\n",
    "    \"\"\"\n",
    "\n",
    "    return data - get_trend(data, dim=dim, deg=deg)\n",
    "\n",
    "\n",
    "def get_empirical_pdf(x):\n",
    "    \"\"\"\n",
    "    Estimate the \"empirical\" probability distribution function for the data x.\n",
    "    In this case the result is a normalized histogram,\n",
    "    Normalized means that integrating over the histogram yields 1.\n",
    "    Returns the PDF (normalized histogram) and edges of the histogram bins\n",
    "    \"\"\"\n",
    "\n",
    "    ## compute histogram\n",
    "    hist, bin_edges = np.histogram(x)\n",
    "\n",
    "    ## normalize to a probability distribution (PDF)\n",
    "    bin_width = bin_edges[1:] - bin_edges[:-1]\n",
    "    pdf = hist / (hist * bin_width).sum()\n",
    "\n",
    "    return pdf, bin_edges\n",
    "\n",
    "\n",
    "def get_gaussian_best_fit(x):\n",
    "    \"\"\"Get gaussian best fit to data, and evaluate\n",
    "    probabilities over the range of the data.\"\"\"\n",
    "\n",
    "    ## get normal distribution best fit\n",
    "    gaussian = scipy.stats.norm(loc=x.mean(), scale=x.std())\n",
    "\n",
    "    ## evaluate over range of data\n",
    "    amp = np.max(np.abs(x.values))\n",
    "    x_eval = np.linspace(-amp, amp)\n",
    "    pdf_eval = gaussian.pdf(x_eval)\n",
    "\n",
    "    return pdf_eval, x_eval\n",
    "\n",
    "\n",
    "def swap_longitude_range(data):\n",
    "    \"\"\"swap longitude range of xr.DataArray from [0,360) to (-180, 180]\"\"\"\n",
    "\n",
    "    ## copy of longitude coordinate to be modified\n",
    "    new_longitude = copy.deepcopy(data.longitude.values)\n",
    "\n",
    "    ## find index where longitude first exceeds 180.\n",
    "    ## (note: np.argmax returns first instance of \"True\" in boolean array)\n",
    "    swap_idx = np.argmax(new_longitude > 180)\n",
    "\n",
    "    ## relabel values >180\n",
    "    new_longitude[swap_idx:] = -360 + new_longitude[swap_idx:]\n",
    "\n",
    "    ## add this coordinate back to the array\n",
    "    data[\"longitude\"] = new_longitude\n",
    "\n",
    "    ## \"roll\" the data to be centered at zero\n",
    "    data = data.roll({\"longitude\": -swap_idx}, roll_coords=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5bd9a1-60a1-4d16-ad38-12c57c595e4f",
   "metadata": {},
   "source": [
    "## Set up Dask dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1fca5a-c33e-4a4f-bffe-05cf4eaea1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up local cluster on dask\n",
    "client = dask.distributed.Client()\n",
    "\n",
    "## display information about cluster (including address of dashboard)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333948ce-71b3-45c2-a758-89326cac7d36",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6c734-1928-4db8-8275-f3e375ab5d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_simulation(varname, member_id, simulation_type, preprocess_func=None):\n",
    "    \"\"\"\n",
    "    Load dataset for single simulation, for single variable.\n",
    "    Arguments:\n",
    "        - varname: name of variable to load, one of {\"SST\",\"PSL\"}\n",
    "        - member_id: ID of ensemble member to load, an integer in the range [1,10]\n",
    "        - simulation_type: one of {\"hist\", \"rcp85\"}\n",
    "        - preprocess func: optional preprocessing function to apply to the simulation\n",
    "    Returns:\n",
    "        - xarray dataarray with given data\n",
    "    \"\"\"\n",
    "\n",
    "    #### 1. get filepath to data\n",
    "    data_fp = SERVER_FP / LENS_FP / pathlib.Path(varname)\n",
    "\n",
    "    #### 2. get naming pattern for files to open\n",
    "    if simulation_type == \"hist\":\n",
    "        file_pattern = f\"*20TRC*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    elif simulation_type == \"rcp85\":\n",
    "        file_pattern = f\"*RCP85*.{member_id:03d}.*.nc\"\n",
    "\n",
    "    else:\n",
    "        print(\"Not a valid simulation type\")\n",
    "\n",
    "    #### 3. open the relevant datasets, applying preprocessing function\n",
    "    data = xr.open_mfdataset(\n",
    "        paths=data_fp.glob(file_pattern),\n",
    "        preprocess=preprocess_func,\n",
    "    )\n",
    "\n",
    "    return data[varname].isel(z_t=0, drop=True)\n",
    "\n",
    "\n",
    "def trim(data, lon_range=[100, 300], lat_range=[-30, 30]):\n",
    "    \"\"\"select part of data in given longitude/latitude range\"\"\"\n",
    "\n",
    "    ## helper function to check if 'x' is in 'x_range'\n",
    "    isin_range = lambda x, x_range: (x_range[0] <= x) & (x <= x_range[1])\n",
    "\n",
    "    ## get mask for data in given lon/lat range\n",
    "    in_lon_range = isin_range(data[\"TLONG\"], lon_range)\n",
    "    in_lat_range = isin_range(data[\"TLAT\"], lat_range)\n",
    "    in_lonlat_range = in_lon_range & in_lat_range\n",
    "\n",
    "    ## load to memory\n",
    "    in_lonlat_range.load()\n",
    "\n",
    "    ## Retain all points with at least one valid grid cell\n",
    "    x_idx = in_lonlat_range.any(\"nlat\")\n",
    "    y_idx = in_lonlat_range.any(\"nlon\")\n",
    "\n",
    "    ## select given points\n",
    "    return data.isel(nlon=x_idx, nlat=y_idx)\n",
    "\n",
    "\n",
    "# import xesmf as xe\n",
    "\n",
    "# # create regular lon/lat grid\n",
    "# grid = xr.DataArray(\n",
    "#     data=None,\n",
    "#     coords={\"lon\": np.arange(0, 360), \"lat\": np.arange(-90, 91)},\n",
    "#     dims=[\"lon\", \"lat\"],\n",
    "# )\n",
    "\n",
    "# ## do the regridding\n",
    "# regridder = xe.Regridder(\n",
    "#     ds_in=data.isel(time=0).rename({\"TLAT\":\"lat\", \"TLON\":\"lon\"}),\n",
    "#     ds_out=grid,\n",
    "#     method=\"bilinear\"\n",
    "# )\n",
    "# data_regrid = regridder(data.rename({\"TLAT\":\"lat\",\"TLONG\":\"lon\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c1153-42e1-49a6-ae27-4c70d7c6f1dd",
   "metadata": {},
   "source": [
    "#### Filepaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c23d58-8fc5-4616-a803-2c08f5fde935",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Path to file server\n",
    "SERVER_FP = pathlib.Path(\"/Volumes\")\n",
    "\n",
    "## Filepath to the CESM LENS dataset\n",
    "LENS_FP = pathlib.Path(\"cmip6/data/cmip6/CMIP/NCAR/LENS\")\n",
    "\n",
    "data = load_simulation(\"SST\", 1, \"hist\", preprocess_func=trim)\n",
    "# data.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
